{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/caroline/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk imports\n",
    "from nltk import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_scorer(pipeline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    print('train score:', pipeline.score(X_train, y_train))\n",
    "    print('accuracy score:', accuracy_score(y_test, preds))\n",
    "    #print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop = stopwords.words('english')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.lower().strip()\n",
    "    final_text = []\n",
    "    for w in text.split():\n",
    "        if w not in stop:\n",
    "            final_text.append(stemmer.stem(w.strip()))\n",
    "    return ' '.join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>ep_title_x</th>\n",
       "      <th>text</th>\n",
       "      <th>ep_title_formatted</th>\n",
       "      <th>airdate</th>\n",
       "      <th>ep_title_y</th>\n",
       "      <th>number</th>\n",
       "      <th>rating</th>\n",
       "      <th>season</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPOCK</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>Check the circuit.</td>\n",
       "      <td>thecage</td>\n",
       "      <td>27 Nov. 1988</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPOCK</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>It can't be the screen then.</td>\n",
       "      <td>thecage</td>\n",
       "      <td>27 Nov. 1988</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPOCK</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>Definitely something out there, Captain, heade...</td>\n",
       "      <td>thecage</td>\n",
       "      <td>27 Nov. 1988</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPOCK</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>Their call letters check with a survey expedit...</td>\n",
       "      <td>thecage</td>\n",
       "      <td>27 Nov. 1988</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPOCK</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>SS Columbia.</td>\n",
       "      <td>thecage</td>\n",
       "      <td>27 Nov. 1988</td>\n",
       "      <td>The Cage</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character ep_title_x                                               text  \\\n",
       "0     SPOCK   The Cage                                 Check the circuit.   \n",
       "1     SPOCK   The Cage                       It can't be the screen then.   \n",
       "2     SPOCK   The Cage  Definitely something out there, Captain, heade...   \n",
       "3     SPOCK   The Cage  Their call letters check with a survey expedit...   \n",
       "4     SPOCK   The Cage                                       SS Columbia.   \n",
       "\n",
       "  ep_title_formatted       airdate ep_title_y  number  rating  season  index  \n",
       "0            thecage  27 Nov. 1988   The Cage       0     7.7       1      1  \n",
       "1            thecage  27 Nov. 1988   The Cage       0     7.7       1      1  \n",
       "2            thecage  27 Nov. 1988   The Cage       0     7.7       1      1  \n",
       "3            thecage  27 Nov. 1988   The Cage       0     7.7       1      1  \n",
       "4            thecage  27 Nov. 1988   The Cage       0     7.7       1      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tos = pd.read_csv('./merged_tos.csv')\n",
    "tos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "      <th>ep_title_formatted</th>\n",
       "      <th>airdate</th>\n",
       "      <th>ep_title_y</th>\n",
       "      <th>number</th>\n",
       "      <th>rating</th>\n",
       "      <th>season</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>You will agree, Data, that Starfleet's orders ...</td>\n",
       "      <td>encounteratfarpoint</td>\n",
       "      <td>26 Sep. 1987</td>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>As simple as that.</td>\n",
       "      <td>encounteratfarpoint</td>\n",
       "      <td>26 Sep. 1987</td>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>It's hardly simple, Data, to negotiate a frien...</td>\n",
       "      <td>encounteratfarpoint</td>\n",
       "      <td>26 Sep. 1987</td>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>Data, how can you be programmed as a virtual e...</td>\n",
       "      <td>encounteratfarpoint</td>\n",
       "      <td>26 Sep. 1987</td>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>It means to spy, to sneak.</td>\n",
       "      <td>encounteratfarpoint</td>\n",
       "      <td>26 Sep. 1987</td>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                               text  \\\n",
       "0    PICARD  You will agree, Data, that Starfleet's orders ...   \n",
       "1    PICARD                                 As simple as that.   \n",
       "2    PICARD  It's hardly simple, Data, to negotiate a frien...   \n",
       "3    PICARD  Data, how can you be programmed as a virtual e...   \n",
       "4    PICARD                         It means to spy, to sneak.   \n",
       "\n",
       "    ep_title_formatted       airdate             ep_title_y  number  rating  \\\n",
       "0  encounteratfarpoint  26 Sep. 1987  Encounter at Farpoint       1     6.9   \n",
       "1  encounteratfarpoint  26 Sep. 1987  Encounter at Farpoint       1     6.9   \n",
       "2  encounteratfarpoint  26 Sep. 1987  Encounter at Farpoint       1     6.9   \n",
       "3  encounteratfarpoint  26 Sep. 1987  Encounter at Farpoint       1     6.9   \n",
       "4  encounteratfarpoint  26 Sep. 1987  Encounter at Farpoint       1     6.9   \n",
       "\n",
       "   season  index  \n",
       "0       1      1  \n",
       "1       1      1  \n",
       "2       1      1  \n",
       "3       1      1  \n",
       "4       1      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tng = pd.read_csv('./merged_tng.csv')\n",
    "tng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "      <th>ep_title_formatted</th>\n",
       "      <th>airdate</th>\n",
       "      <th>ep_title_y</th>\n",
       "      <th>number</th>\n",
       "      <th>rating</th>\n",
       "      <th>season</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOCUTUS</td>\n",
       "      <td>Resistance is futile.</td>\n",
       "      <td>emissary</td>\n",
       "      <td>3 Jan. 1993</td>\n",
       "      <td>Emissary</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOCUTUS</td>\n",
       "      <td>You will disarm your weapons and escort us to ...</td>\n",
       "      <td>emissary</td>\n",
       "      <td>3 Jan. 1993</td>\n",
       "      <td>Emissary</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOCUTUS</td>\n",
       "      <td>If you attempt to intervene, we will destroy you.</td>\n",
       "      <td>emissary</td>\n",
       "      <td>3 Jan. 1993</td>\n",
       "      <td>Emissary</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOCUTUS</td>\n",
       "      <td>It is malevolent.</td>\n",
       "      <td>emissary</td>\n",
       "      <td>3 Jan. 1993</td>\n",
       "      <td>Emissary</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOCUTUS</td>\n",
       "      <td>Destroy it now.</td>\n",
       "      <td>emissary</td>\n",
       "      <td>3 Jan. 1993</td>\n",
       "      <td>Emissary</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                               text  \\\n",
       "0   LOCUTUS                              Resistance is futile.   \n",
       "1   LOCUTUS  You will disarm your weapons and escort us to ...   \n",
       "2   LOCUTUS  If you attempt to intervene, we will destroy you.   \n",
       "3   LOCUTUS                                  It is malevolent.   \n",
       "4   LOCUTUS                                    Destroy it now.   \n",
       "\n",
       "  ep_title_formatted      airdate ep_title_y  number  rating  season  index  \n",
       "0           emissary  3 Jan. 1993   Emissary       1     7.5       1      1  \n",
       "1           emissary  3 Jan. 1993   Emissary       1     7.5       1      1  \n",
       "2           emissary  3 Jan. 1993   Emissary       1     7.5       1      1  \n",
       "3           emissary  3 Jan. 1993   Emissary       1     7.5       1      1  \n",
       "4           emissary  3 Jan. 1993   Emissary       1     7.5       1      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds9 = pd.read_csv('./merged_df.csv')\n",
    "ds9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kirk = tos.loc[tos['character'] == 'KIRK'][['character', 'text']]\n",
    "picard = tng.loc[tng['character'] == 'PICARD'][['character', 'text']]\n",
    "sisko = ds9.loc[ds9['character'] == 'SISKO'][['character', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = kirk.append(picard).append(sisko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = [len(word_tokenize(line)) > 5 for line in cap['text']]\n",
    "cap_5 = cap[count_array]\n",
    "\n",
    "count_array = [len(word_tokenize(line)) > 8 for line in cap['text']]\n",
    "cap_8 = cap[count_array]\n",
    "\n",
    "count_array = [len(word_tokenize(line)) > 10 for line in cap['text']]\n",
    "cap_10 = cap[count_array]\n",
    "\n",
    "count_array = [len(word_tokenize(line)) > 15 for line in cap['text']]\n",
    "cap_15 = cap[count_array]\n",
    "\n",
    "count_array = [len(word_tokenize(line)) > 20 for line in cap['text']]\n",
    "cap_20 = cap[count_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_caps = [cap_5, cap_8, cap_10, cap_15, cap_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PICARD    20883\n",
       "KIRK      17001\n",
       "SISKO     14023\n",
       "Name: character, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap['character'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40231567996609319"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "cap['character'].value_counts().values[0]/cap.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICARD    13696\n",
      "KIRK      10219\n",
      "SISKO      9525\n",
      "Name: character, dtype: int64\n",
      "baseline: 0.40956937799 \n",
      "\n",
      "PICARD    8611\n",
      "SISKO     5943\n",
      "KIRK      5419\n",
      "Name: character, dtype: int64\n",
      "baseline: 0.431132028238 \n",
      "\n",
      "PICARD    5955\n",
      "SISKO     4173\n",
      "KIRK      3522\n",
      "Name: character, dtype: int64\n",
      "baseline: 0.436263736264 \n",
      "\n",
      "PICARD    2287\n",
      "SISKO     1662\n",
      "KIRK      1252\n",
      "Name: character, dtype: int64\n",
      "baseline: 0.439723130167 \n",
      "\n",
      "PICARD    854\n",
      "SISKO     611\n",
      "KIRK      434\n",
      "Name: character, dtype: int64\n",
      "baseline: 0.449710373881 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in all_caps:\n",
    "    print(each['character'].value_counts())\n",
    "    print('baseline:', each['character'].value_counts().values[0]/each.shape[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KIRK', 'PICARD', 'SISKO']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(cap['character'])\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.942145135566\n",
      "accuracy score: 0.582057416268\n",
      "None\n",
      "train score: 0.977101275118\n",
      "accuracy score: 0.576091309571\n",
      "None\n",
      "train score: 0.982025984175\n",
      "accuracy score: 0.588631702315\n",
      "None\n",
      "train score: 0.981282051282\n",
      "accuracy score: 0.60568793236\n",
      "None\n",
      "train score: 0.977528089888\n",
      "accuracy score: 0.574736842105\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(rfc_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.963157894737\n",
      "accuracy score: 0.562200956938\n",
      "None\n",
      "train score: 0.985179250951\n",
      "accuracy score: 0.561674008811\n",
      "None\n",
      "train score: 0.984663475628\n",
      "accuracy score: 0.574274831527\n",
      "None\n",
      "train score: 0.984615384615\n",
      "accuracy score: 0.576479631053\n",
      "None\n",
      "train score: 0.983848314607\n",
      "accuracy score: 0.597894736842\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = make_pipeline(\n",
    "    CountVectorizer(preprocessor=cleaner),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(rfc_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ada, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.523803827751\n",
      "accuracy score: 0.522966507177\n",
      "None\n",
      "train score: 0.553107684091\n",
      "accuracy score: 0.557268722467\n",
      "None\n",
      "train score: 0.574680082055\n",
      "accuracy score: 0.564605918547\n",
      "None\n",
      "train score: 0.598717948718\n",
      "accuracy score: 0.574173712529\n",
      "None\n",
      "train score: 0.65308988764\n",
      "accuracy score: 0.545263157895\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ada_pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(ada_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.523923444976\n",
      "accuracy score: 0.523803827751\n",
      "None\n",
      "train score: 0.558782295213\n",
      "accuracy score: 0.550060072087\n",
      "None\n",
      "train score: 0.570186578099\n",
      "accuracy score: 0.564312921184\n",
      "None\n",
      "train score: 0.604102564103\n",
      "accuracy score: 0.571099154497\n",
      "None\n",
      "train score: 0.653792134831\n",
      "accuracy score: 0.547368421053\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ada_pipe = make_pipeline(\n",
    "    CountVectorizer(preprocessor=cleaner),\n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(ada_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.937878787879\n",
      "accuracy score: 0.569019138756\n",
      "None\n",
      "train score: 0.970291741772\n",
      "accuracy score: 0.561273528234\n",
      "None\n",
      "train score: 0.97460193416\n",
      "accuracy score: 0.571051860533\n",
      "None\n",
      "train score: 0.977179487179\n",
      "accuracy score: 0.5618754804\n",
      "None\n",
      "train score: 0.962078651685\n",
      "accuracy score: 0.528421052632\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bag_pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    BaggingClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']b\n",
    "    bag_pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    BaggingClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(bag_pipe))\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(bag_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.959210526316\n",
      "accuracy score: 0.56028708134\n",
      "None\n",
      "train score: 0.976967754857\n",
      "accuracy score: 0.57148578294\n",
      "None\n",
      "train score: 0.974894988766\n",
      "accuracy score: 0.584236741869\n",
      "None\n",
      "train score: 0.972820512821\n",
      "accuracy score: 0.568024596464\n",
      "None\n",
      "train score: 0.974719101124\n",
      "accuracy score: 0.595789473684\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bag_pipe = make_pipeline(\n",
    "    CountVectorizer(preprocessor=cleaner),\n",
    "    BaggingClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(bag_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.965350877193\n",
      "accuracy score: 0.569377990431\n",
      "None\n",
      "train score: 0.984244609119\n",
      "accuracy score: 0.580296355627\n",
      "None\n",
      "train score: 0.985347269708\n",
      "accuracy score: 0.574860826253\n",
      "None\n",
      "train score: 0.984358974359\n",
      "accuracy score: 0.578016910069\n",
      "None\n",
      "train score: 0.982443820225\n",
      "accuracy score: 0.555789473684\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = make_pipeline(\n",
    "    TfidfVectorizer(preprocessor=cleaner),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(rfc_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.524362041467\n",
      "accuracy score: 0.522488038278\n",
      "None\n",
      "train score: 0.556846251419\n",
      "accuracy score: 0.554865839007\n",
      "None\n",
      "train score: 0.572824069552\n",
      "accuracy score: 0.56782888954\n",
      "None\n",
      "train score: 0.601794871795\n",
      "accuracy score: 0.594926979247\n",
      "None\n",
      "train score: 0.663623595506\n",
      "accuracy score: 0.555789473684\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ada_pipe = make_pipeline(\n",
    "    TfidfVectorizer(preprocessor=cleaner),\n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(ada_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.958094098884\n",
      "accuracy score: 0.57523923445\n",
      "None\n",
      "train score: 0.979237599306\n",
      "accuracy score: 0.579295154185\n",
      "None\n",
      "train score: 0.977727849956\n",
      "accuracy score: 0.566363902725\n",
      "None\n",
      "train score: 0.978717948718\n",
      "accuracy score: 0.564950038432\n",
      "None\n",
      "train score: 0.980337078652\n",
      "accuracy score: 0.591578947368\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bag_pipe = make_pipeline(\n",
    "    TfidfVectorizer(preprocessor=cleaner),\n",
    "    BaggingClassifier()\n",
    ")\n",
    "\n",
    "for l in all_caps:\n",
    "    X = l['text']\n",
    "    y = le.transform(l['character'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    print(classification_scorer(bag_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
