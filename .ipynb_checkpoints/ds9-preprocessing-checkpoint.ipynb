{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is to iron out what pre-processing steps I want to take before modeling. Those pre-processing steps will be duplicated in my modeling notebook once decided upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_union, make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_chars = df['character'].value_counts()[:10].index\n",
    "\n",
    "common_chars_df = df.loc[df['character'].isin(common_chars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SISKO', \"O'BRIEN\", 'KIRA', 'ODO', 'QUARK', 'BASHIR', 'DAX',\n",
       "       'DUKAT', 'GARAK', 'WORF'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_chars_df['character'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop all sentences shorter than five words\n",
    "count_array = [len(word_tokenize(line)) > 5 for line in common_chars_df['text']]\n",
    "df = common_chars_df[count_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SISKO', \"O'BRIEN\", 'KIRA', 'ODO', 'QUARK', 'BASHIR', 'DAX',\n",
       "       'DUKAT', 'GARAK', 'WORF'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['character'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop = stopwords_list\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.lower().strip()\n",
    "    final_text = []\n",
    "    for w in text.split():\n",
    "        if w.strip() not in stop:\n",
    "            final_text.append(stemmer.stem(w.strip()))\n",
    "    return ' '.join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventur\n",
      "hero made\n",
      "wilder\n",
      "didnt mean\n",
      "mean construct\n",
      "theyv listen reason havent\n",
      "warn happen\n",
      "believ cardassian ever attack feder outpost\n",
      "look attent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in df[df['character'] == 'BASHIR']['text'][5:15]:\n",
    "    print(cleaner(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "im            2743\n",
       "go            2584\n",
       "dont          2437\n",
       "know          2211\n",
       "get           1985\n",
       "one           1913\n",
       "want          1804\n",
       "well          1708\n",
       "your          1635\n",
       "think         1557\n",
       "like          1512\n",
       "time          1259\n",
       "us            1167\n",
       "would         1160\n",
       "take          1133\n",
       "that          1103\n",
       "see           1066\n",
       "could         1056\n",
       "right         1056\n",
       "way           1052\n",
       "look           999\n",
       "make           995\n",
       "ill            987\n",
       "say            954\n",
       "ive            929\n",
       "tell           904\n",
       "back           898\n",
       "let            862\n",
       "come           860\n",
       "need           851\n",
       "station        833\n",
       "ship           825\n",
       "thing          822\n",
       "cant           804\n",
       "tri            773\n",
       "two            747\n",
       "someth         747\n",
       "there          739\n",
       "command        730\n",
       "find           719\n",
       "cardassian     706\n",
       "never          688\n",
       "talk           673\n",
       "peopl          663\n",
       "got            647\n",
       "didnt          634\n",
       "sure           632\n",
       "he             630\n",
       "id             602\n",
       "work           581\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(preprocessor=cleaner)\n",
    "cv.fit(df['text'])\n",
    "to_dense = cv.transform(df['text']).todense()\n",
    "to_dense_df = pd.DataFrame(to_dense, columns=cv.get_feature_names())\n",
    "to_dense_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['im', 'go', 'dont', 'know', 'get', 'one', 'want', 'well', 'your',\n",
       "       'think', 'like', 'time', 'us', 'would', 'take', 'that', 'see', 'could',\n",
       "       'right', 'way', 'look', 'make', 'ill', 'say', 'ive', 'tell', 'back',\n",
       "       'let', 'come', 'need', 'station', 'ship', 'thing', 'cant', 'tri', 'two',\n",
       "       'someth', 'there', 'command', 'find', 'cardassian', 'never', 'talk',\n",
       "       'peopl', 'got', 'didnt', 'sure', 'he', 'id', 'work'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dense_df.sum().sort_values(ascending=False).index[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_list.extend(['im', 'go', 'dont', 'know', 'get', 'one', 'want', 'well', 'your',\n",
    "       'think', 'like', 'us', 'would', 'take', 'that', 'see', 'could',\n",
    "       'right', 'way', 'make', 'ill', 'say', 'ive', 'tell', 'back',\n",
    "       'let', 'come', 'thing', 'cant', 'tri', 'two',\n",
    "       'someth', 'there', 'find', 'talk', 'got', 'didn\\t', 'sure', 'he', 'id', 'work'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "go            1805\n",
       "your          1635\n",
       "time          1259\n",
       "that          1103\n",
       "look           999\n",
       "need           851\n",
       "station        833\n",
       "ship           825\n",
       "tri            773\n",
       "someth         747\n",
       "there          739\n",
       "command        730\n",
       "cardassian     706\n",
       "never          688\n",
       "peopl          663\n",
       "didnt          634\n",
       "he             630\n",
       "theyr          580\n",
       "doctor         577\n",
       "day            567\n",
       "good           566\n",
       "much           558\n",
       "use            555\n",
       "still          544\n",
       "mean           538\n",
       "klingon        537\n",
       "help           535\n",
       "give           532\n",
       "first          529\n",
       "chief          516\n",
       "littl          513\n",
       "three          509\n",
       "major          506\n",
       "even           504\n",
       "better         496\n",
       "believ         489\n",
       "mayb           489\n",
       "long           484\n",
       "thought        481\n",
       "captain        477\n",
       "starfleet      474\n",
       "bajoran        473\n",
       "oh             471\n",
       "might          453\n",
       "anyth          449\n",
       "year           443\n",
       "odo            438\n",
       "man            438\n",
       "ask            435\n",
       "youv           430\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(preprocessor=cleaner)\n",
    "cv.fit(df['text'])\n",
    "to_dense = cv.transform(df['text']).todense()\n",
    "to_dense_df = pd.DataFrame(to_dense, columns=cv.get_feature_names())\n",
    "to_dense_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['go', 'your', 'time', 'that', 'look', 'need', 'station', 'ship', 'tri',\n",
       "       'someth', 'there', 'command', 'cardassian', 'never', 'peopl', 'didnt',\n",
       "       'he', 'theyr', 'doctor', 'day', 'good', 'much', 'use', 'still', 'mean',\n",
       "       'klingon', 'help', 'give', 'first', 'chief', 'littl', 'three', 'major',\n",
       "       'even', 'better', 'believ', 'mayb', 'long', 'thought', 'captain',\n",
       "       'starfleet', 'bajoran', 'oh', 'might', 'anyth', 'year', 'odo', 'man',\n",
       "       'ask', 'youv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dense_df.sum().sort_values(ascending=False).index[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_list.extend(to_dense_df.sum()[to_dense_df.sum() < 5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_list.extend(['go', 'your', 'theyr', 'day', 'much', 'use', 'still', 'mean', 'thought', 'oh', 'anyth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "go            1805\n",
       "your          1635\n",
       "time          1259\n",
       "that          1103\n",
       "look           999\n",
       "need           851\n",
       "station        833\n",
       "ship           825\n",
       "tri            773\n",
       "someth         747\n",
       "there          739\n",
       "command        730\n",
       "cardassian     706\n",
       "never          688\n",
       "peopl          663\n",
       "didnt          634\n",
       "he             630\n",
       "theyr          580\n",
       "doctor         577\n",
       "good           566\n",
       "klingon        537\n",
       "help           535\n",
       "give           532\n",
       "first          529\n",
       "chief          516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(preprocessor=cleaner)\n",
    "cv.fit(df['text'])\n",
    "to_dense = cv.transform(df['text']).todense()\n",
    "to_dense_df = pd.DataFrame(to_dense, columns=cv.get_feature_names())\n",
    "to_dense_df.sum().sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventur\n",
      "hero made\n",
      "wilder\n",
      "didnt\n",
      "construct\n",
      "theyv listen reason havent\n",
      "warn happen\n",
      "believ cardassian ever attack feder outpost\n",
      "look attent\n",
      "\n",
      "thirteen injur command fatal\n",
      "walk along odo someon practic phaser around\n",
      "\n",
      "\n",
      "quark found delight dri champagn estat bottl korri\n",
      "cold hand warm heart\n",
      "exot your wear\n",
      "ye ye\n",
      "free\n",
      "guess competit\n",
      "nice dinner command sisko\n",
      "said tri rise suggest alway succeed\n",
      "champagn ice\n",
      "caus death mysteri\n",
      "knife directli left thorac vertebra perfor lower ventricl heart\n",
      "murder appar decent knowledg bajoran anatomi\n",
      "sweep hair follicl skin cellular remnant dna fragment\n",
      "dna sequenc analys cellular spectrograph particul matter trace\n",
      "ask lieuten dax confirm find afraid concur\n",
      "apart bodi discov dna present weve identifi ibudan\n",
      "curiou found seofuran fragment near matter reclam unit\n",
      "appear tri rid\n",
      "exactli theyr\n",
      "time\n",
      "analys fragment detect trace complex organ structur\n",
      "suggest ibudan may conduct sort medic experi board ship\n",
      "let standard electrophoret analysi tell\n",
      "complex protein break dna fragment\n",
      "mean set bioregen field acceler cellular develop\n",
      "reconstruct dna sequenc might give idea\n",
      "go increas metabol field energi\n",
      "that look there genet drift quit put finger\n",
      "go wait becom clue\n",
      "transfer larger field\n",
      "mani differ live she led\n"
     ]
    }
   ],
   "source": [
    "for each in df[df['character'] == 'BASHIR']['text'][5:50]:\n",
    "    print(cleaner(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'go' in stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
